{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/h8cjd1kx3r52swkrn4nnzzhh0000gn/T/ipykernel_17033/2441700993.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%matplotlib widget \n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and display the sessions \n",
    "animal=\"WI\" # \"FN\" or \"WI\" \n",
    "data_file = f\"/Users/withercp/Documents/dev/brainhack/data/TH_task_{animal}_singleprobe_500ms.h5\"\n",
    "assert os.path.exists(data_file), \"File not found: {data_file}\".format(data_file=data_file)\n",
    "\n",
    "with h5py.File(data_file, 'r') as f:\n",
    "    sessions = list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['binned_spike', 'epoch', 'meta', 'rem_rec', 'trial']>\n"
     ]
    }
   ],
   "source": [
    "# Load data for a particular session and view the format of the data\n",
    "i = 0\n",
    "session = sessions[i]\n",
    "# convert mm-dd-yyyy to mm/dd/yyyy\n",
    "date_str = session.replace('-', '/')\n",
    "\n",
    "with h5py.File(data_file, 'r') as f:\n",
    "    print(f[sessions[i]].keys())\n",
    "    epoc_np=np.array(f[sessions[i]]['epoch'])\n",
    "    rem_rec_np=np.array(f[sessions[i]]['rem_rec'])\n",
    "    trial_np=np.array(f[sessions[i]]['trial'])\n",
    "    binned_spike_np = np.array(f[sessions[i]]['binned_spike'])\n",
    "    meta = np.array(f[sessions[i]]['meta'])\n",
    "\n",
    "rem_rec_bin = np.array([1 if x == b'Remote' else 0 for x in rem_rec_np])\n",
    "\n",
    "block_num = 0\n",
    "block_nums = np.zeros(len(rem_rec_bin), dtype=int)  # Initialize array with zeros\n",
    "\n",
    "for i in range(1, len(rem_rec_bin)):\n",
    "    if rem_rec_bin[i] != rem_rec_bin[i-1]:  # If trial type changes\n",
    "        block_num += 1  # Increment block number\n",
    "    block_nums[i] = block_num  # Assign block number to current trial\n",
    "\n",
    "unique_blocks = np.unique(block_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct and incorrect trials per screen (I still need approval to use this data)\n",
    "\n",
    "'''\n",
    "df = pd.read_csv(\"Y:/LAMBDA/Sub-Project/SLUR(..)/data/FN/FN_TT_ALL_refined.csv\")\n",
    "df = df[df['Date'] == date_str]\n",
    "print(df.head())\n",
    "\n",
    "screen_correct = np.zeros((4, df['TrialNum'].max()))\n",
    "screen_correct[0, :] = df[\"Correct\"][::4]\n",
    "screen_correct[1, :] = df[\"Correct\"][1::4]\n",
    "screen_correct[2, :] = df[\"Correct\"][2::4]\n",
    "screen_correct[3, :] = df[\"Correct\"][3::4]\n",
    "screen_correct_drift = screen_correct[:, :-1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep rows where in at least one bin, the neuron fired at least 500 times \n",
    "# (i.e. the neuron is not active in that bin)\n",
    "\n",
    "rows_to_keep = [] \n",
    "for i in unique_blocks:\n",
    "    for j in range(binned_spike_np.shape[0]):\n",
    "        if np.sum(binned_spike_np[j, block_nums == i]) >= 500:\n",
    "            rows_to_keep.append(j)\n",
    "\n",
    "rows_to_keep = np.unique(rows_to_keep)\n",
    "\n",
    "binned_spike_np = binned_spike_np[rows_to_keep, :]\n",
    "\n",
    "# Normalize binned spike data \n",
    "binned_spike_np_z = scipy.stats.zscore(binned_spike_np, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Simple logistic regression classifier to predict behavior (classification) from low dimensional data (data)\n",
    "\n",
    "def logistic_regression_classifier(data, classification):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, classification, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on all labels\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def PCA_binned_spike_np(X, y):\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(np.transpose(X))\n",
    "    embedding = pca.transform(np.transpose(X))\n",
    "\n",
    "    # Plot PCA embedding and color by value in epoc_np\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(embedding[:,0], embedding[:,1], embedding[:,2], c=y, cmap = 'coolwarm')\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    plt.show()\n",
    "    return embedding\n",
    "\n",
    "PCA_binned_spike_np(binned_spike_np, trial_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def TSNE_binned_spike_np(X, y):\n",
    "    # t-SNE\n",
    "    tsne = TSNE(n_components = 128, perplexity=100)\n",
    "    embedding = tsne.fit_transform(np.transpose(X))\n",
    "\n",
    "    # Plot the first three components in 3d and make the plot interactive\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter_plot = ax.scatter(embedding[:,0], embedding[:,1], embedding[:,2], c = y)\n",
    "    ax.set_xlabel('t-SNE1')\n",
    "    ax.set_ylabel('t-SNE2')\n",
    "    ax.set_zlabel('t-SNE3')\n",
    "    plt.show()\n",
    "\n",
    "    return embedding\n",
    "\n",
    "TSNE_binned_spike_np(binned_spike_np, trial_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optuna (bayesian optimization) to find the best hyperparameters for t-SNE to maximize classification accuracy\n",
    "\n",
    "import optuna\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = binned_spike_np # neural data\n",
    "y = rem_rec_np # classification labels\n",
    "\n",
    "# Simple logistic regression classifier to predict behavior (classification) from low dimensional data (data)\n",
    "def logistic_regression_classifier(data, classification):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, classification, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the t-SNE object with the hyperparameters to optimize\n",
    "    tsne = TSNE(\n",
    "        n_components=3,\n",
    "        perplexity=trial.suggest_int('perplexity', 5, len(y)-1),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 10, 100),\n",
    "        n_iter=trial.suggest_int('n_iter', 250, 1000),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Transform the data with t-SNE\n",
    "    tsne_embedding = tsne.fit_transform(np.transpose(X))\n",
    "    accuracy = logistic_regression_classifier(tsne_embedding, y)\n",
    "    return accuracy\n",
    "\n",
    "# Define the study object for Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the hyperparameters with Optuna\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best parameters: \", study.best_params)\n",
    "print(\"Best score: \", study.best_value)\n",
    "\n",
    "# Plot the t-SNE embedding with the best hyperparameters\n",
    "tsne = TSNE(\n",
    "    n_components=3,\n",
    "    perplexity=study.best_params['perplexity'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    n_iter=study.best_params['n_iter'],\n",
    "    random_state=42\n",
    ")\n",
    "tsne_embedding = tsne.fit_transform(np.transpose(X))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(tsne_embedding[:,0], tsne_embedding[:,1], tsne_embedding[:,2], c=y, cmap='jet')\n",
    "ax.set_xlabel('t-SNE1')\n",
    "ax.set_ylabel('t-SNE2')\n",
    "ax.set_zlabel('t-SNE3')\n",
    "ax.set_title('t-SNE on Block Segment (Firing Rate)')\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "score = cross_val_score(clf, tsne_embedding, y, cv=5).mean()\n",
    "print(\"Classification accuracy for remote/recent:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def UMAP_neural(X = binned_spike_np, y = trial_np, params = {'n_dims':3, 'metric': 'euclidean', 'n_neighbors':200, 'min_dist':0.2, 'init': 'spectral'}): \n",
    "    reducer = umap.UMAP(n_components=128, n_neighbors=params['n_neighbors'], min_dist=params['min_dist'], metric=params['metric'], init='spectral', random_state=42)\n",
    "    scaled_block_firing_rate = StandardScaler().fit_transform(np.transpose(X))\n",
    "    embedding = reducer.fit_transform(scaled_block_firing_rate)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter_plot = ax.scatter(embedding[:,0], embedding[:,1], embedding[:,2], c = epoc_np, cmap='coolwarm')\n",
    "    ax.set_xlabel('UMAP1')\n",
    "    ax.set_ylabel('UMAP2')\n",
    "    ax.set_zlabel('UMAP3')\n",
    "    #fig.colorbar(scatter_plot, ax=ax)\n",
    "    plt.show()\n",
    "    return embedding\n",
    "\n",
    "UMAP_neural()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available: 10\n",
      "Worker 17052 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 200, 'min_dist': 0.6, 'init': 'spectral'}Worker 17051 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 200, 'min_dist': 1.0, 'init': 'spectral'}\n",
      "\n",
      "Worker 17055 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 200, 'min_dist': 0.8, 'init': 'spectral'}\n",
      "Worker 17053 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 200, 'min_dist': 0.2, 'init': 'spectral'}\n",
      "Worker 17054 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 200, 'min_dist': 0.4, 'init': 'spectral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 17051 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 400, 'min_dist': 0.2, 'init': 'spectral'}\n",
      "Worker 17052 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 400, 'min_dist': 0.4, 'init': 'spectral'}\n",
      "Worker 17053 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 400, 'min_dist': 0.6, 'init': 'spectral'}\n",
      "Worker 17054 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 400, 'min_dist': 0.8, 'init': 'spectral'}\n",
      "Worker 17055 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 400, 'min_dist': 1.0, 'init': 'spectral'}\n",
      "Worker 17053 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 600, 'min_dist': 0.2, 'init': 'spectral'}\n",
      "Worker 17055 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 600, 'min_dist': 0.4, 'init': 'spectral'}\n",
      "Worker 17052 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 600, 'min_dist': 0.6, 'init': 'spectral'}\n",
      "Worker 17054 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 600, 'min_dist': 0.8, 'init': 'spectral'}\n",
      "Worker 17051 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 600, 'min_dist': 1.0, 'init': 'spectral'}\n",
      "Worker 17055 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 800, 'min_dist': 0.2, 'init': 'spectral'}\n",
      "Worker 17052 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 800, 'min_dist': 0.4, 'init': 'spectral'}\n",
      "Worker 17053 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 800, 'min_dist': 0.6, 'init': 'spectral'}\n",
      "Worker 17051 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 800, 'min_dist': 0.8, 'init': 'spectral'}\n",
      "Worker 17054 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 800, 'min_dist': 1.0, 'init': 'spectral'}\n",
      "Worker 17055 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1000, 'min_dist': 0.2, 'init': 'spectral'}\n",
      "Worker 17052 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1000, 'min_dist': 0.4, 'init': 'spectral'}\n",
      "Worker 17054 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1000, 'min_dist': 0.6, 'init': 'spectral'}\n",
      "Worker 17053 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1000, 'min_dist': 0.8, 'init': 'spectral'}\n",
      "Worker 17051 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1000, 'min_dist': 1.0, 'init': 'spectral'}\n",
      "Worker 17055 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1200, 'min_dist': 0.2, 'init': 'spectral'}\n",
      "Worker 17052 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1200, 'min_dist': 0.4, 'init': 'spectral'}\n",
      "Worker 17053 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1200, 'min_dist': 0.6, 'init': 'spectral'}\n",
      "Worker 17051 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1200, 'min_dist': 0.8, 'init': 'spectral'}\n",
      "Worker 17054 is tuning hyperparameters: {'n_dims': 3, 'metric': 'euclidean', 'n_neighbors': 1200, 'min_dist': 1.0, 'init': 'spectral'}\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing for UMAP hyperparameter tuning\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Get the number of cores available\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of cores available: {num_cores}\")\n",
    "\n",
    "def UMAP_neural(X = binned_spike_np, y = trial_np, params = {'n_dims':3, 'metric': 'euclidean', 'n_neighbors':200, 'min_dist':0.2, 'init': 'spectral'}):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        print(f\"Worker {os.getpid()} is tuning hyperparameters: {params}\")\n",
    "        reducer = umap.UMAP(n_components=128, n_neighbors=params['n_neighbors'], min_dist=params['min_dist'], metric=params['metric'], init='spectral', random_state=42)\n",
    "        \n",
    "        embedding = reducer.fit_transform(scaled_block_firing_rate)\n",
    "        return params, embedding\n",
    "\n",
    "# Run UMAP with different n_neighbors and min_dist values in parallel\n",
    "n_neighbors = [200, 400, 600, 800, 1000, 1200]\n",
    "min_dist = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "scaled_block_firing_rate = StandardScaler().fit_transform(np.transpose(binned_spike_np))\n",
    "\n",
    "# Running 10 cores at a time across 30 hyperparameter combinations takes around 13 minutes on my computer\n",
    "# I might try reducing num_cores to 5 or 6 to reduce overhead \n",
    "r1 = Parallel(n_jobs=num_cores//2)(delayed(UMAP_neural) (X = scaled_block_firing_rate, y = trial_np, params = {'n_dims':3, 'metric': 'euclidean', 'n_neighbors':i, 'min_dist':j, 'init': 'spectral'}) for i in n_neighbors for j in min_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fd063d38214783a64dc21019bd2393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=200, max=2000, min=200, step=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e4210fd2a9423189ec856f1c829b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, max=1.0, min=0.2, step=0.2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85769252ec734f30979db2a6bbd1effb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=200, description='n_neighbors', max=2000, min=200, step=200), FloatSlideâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_embedding(embedding):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter_plot = ax.scatter(embedding[:, 0], embedding[:, 1], embedding[:, 2], c=trial_np, cmap='coolwarm')\n",
    "    cbar = plt.colorbar(\n",
    "        scatter_plot,\n",
    "\n",
    "    )\n",
    "    cbar.set_label(\"Trial #\")\n",
    "    ax.set_xlabel('UMAP1')\n",
    "    ax.set_ylabel('UMAP2')\n",
    "    ax.set_zlabel('UMAP3')\n",
    "    plt.show()\n",
    "\n",
    "# Slider setup\n",
    "slider_neighbors = widgets.IntSlider(min=200, max=2000, step=200, value=200)\n",
    "slider_dist = widgets.FloatSlider(min=0.2, max=1.0, step=0.2, value=0.2)\n",
    "\n",
    "# Display the sliders\n",
    "display(slider_neighbors)\n",
    "display(slider_dist)\n",
    "\n",
    "n_neighbors = [200, 400, 600, 800, 1000, 1200]\n",
    "min_dist = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "pairs = list(itertools.product(n_neighbors, min_dist))\n",
    "\n",
    "@widgets.interact(n_neighbors=slider_neighbors, min_dist=slider_dist)\n",
    "def update(n_neighbors, min_dist):\n",
    "    for embedding in r1: \n",
    "        if embedding[0]['n_neighbors'] == n_neighbors and embedding[0]['min_dist'] == min_dist:\n",
    "            plot_embedding(embedding[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optuna (bayesian optimization) to find the best hyperparameters for UMAP to maximize classification accuracy \n",
    "\n",
    "import optuna\n",
    "from umap import UMAP\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = binned_spike_np\n",
    "y = rem_rec_np\n",
    "\n",
    "def logistic_regression_classifier(data, classification):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, classification, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    umap = UMAP(\n",
    "        n_components=3,\n",
    "        n_neighbors=trial.suggest_int('n_neighbors', 100, len(y)-1),\n",
    "        min_dist=trial.suggest_float('min_dist', 0.01, 1),\n",
    "        spread=trial.suggest_float('spread', 1.0, 1.5),\n",
    "        metric=trial.suggest_categorical('metric', ['cosine', 'euclidean']), \n",
    "    )\n",
    "    umap_embedding = umap.fit_transform(np.transpose(X))\n",
    "    #accuracy = logistic_regression_classifier(umap_embedding, y)\n",
    "    accuracy = logistic_regression_classifier(umap_embedding)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best parameters: \", study.best_params)\n",
    "print(\"Best score: \", study.best_value)\n",
    "\n",
    "umap = UMAP(\n",
    "    n_components=3,\n",
    "    n_neighbors=study.best_params['n_neighbors'],\n",
    "    min_dist=study.best_params['min_dist'],\n",
    "    spread=study.best_params['spread']\n",
    ")\n",
    "umap_embedding = umap.fit_transform(np.transpose(X))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(umap_embedding[:,0], umap_embedding[:,1], umap_embedding[:,2], c=y, cmap='jet')\n",
    "ax.set_xlabel('UMAP1')\n",
    "ax.set_ylabel('UMAP2')\n",
    "ax.set_zlabel('UMAP3')\n",
    "ax.set_title('UMAP (Firing Rate)')\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "score = cross_val_score(clf, umap_embedding, y, cv=5).mean()\n",
    "print(\"Classification accuracy for remote/recent:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEBRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default cebra model (no behavioral labels) creates a latent space to minimize distance between \n",
    "# points that share similar times \n",
    "\n",
    "from cebra import CEBRA\n",
    "cebra_model = CEBRA(\n",
    "    model_architecture = \"offset10-model\",\n",
    "    batch_size = 1024,\n",
    "    temperature_mode=\"auto\",\n",
    "    learning_rate = 0.001,\n",
    "    max_iterations = 10,\n",
    "    time_offsets = 10,\n",
    "    output_dimension = 3,\n",
    "    device = \"cuda_if_available\",\n",
    "    distance = \"cosine\", \n",
    "    verbose = True\n",
    ")\n",
    "cebra_model.fit(np.transpose(binned_spike_np), trial_np)\n",
    "cebra_time = cebra_model.transform(np.transpose(binned_spike_np))\n",
    "\n",
    "# Plot cebra_time in 3 dimensions\n",
    "y = trial_np\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(cebra_time[:,0], cebra_time[:,1], cebra_time[:,2], c=y, cmap='jet')\n",
    "ax.set_xlabel('CEBRA1')\n",
    "ax.set_ylabel('CEBRA2')\n",
    "ax.set_zlabel('CEBRA3')\n",
    "ax.set_title('CEBRA (Firing Rate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will try to use the behavioral labels to create a latent space that minimizes distance between\n",
    "# points that share similar behaviors. BUT, we shuffle the time labels to see if there really exists \n",
    "# a low dimensional structure that is specific to time \n",
    "\n",
    "trial_np_shuffled = np.random.permutation(trial_np)\n",
    "cebra_model.fit(np.transpose(binned_spike_np), trial_np_shuffled)\n",
    "cebra_time_shuffled = cebra_model.transform(np.transpose(binned_spike_np))\n",
    "\n",
    "# Plot cebra_time in 3 dimensions\n",
    "y = trial_np_shuffled\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(cebra_time_shuffled[:,0], cebra_time_shuffled[:,1], cebra_time_shuffled[:,2], c=y, cmap='jet')\n",
    "ax.set_xlabel('CEBRA1')\n",
    "ax.set_ylabel('CEBRA2')\n",
    "ax.set_zlabel('CEBRA3')\n",
    "ax.set_title('CEBRA (Firing Rate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the smallest model (offset1-model) to see if we can get a better latent space faster\n",
    "\n",
    "import cebra\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "models = ['offset10-model','offset5-model','offset1-model','offset40-model-4x-subsample', 'resample5-model', 'offset36-model', 'offset36-model-dropout']\n",
    "models = ['offset1-model']\n",
    "embeddings = []\n",
    "X = binned_spike_np\n",
    "y = np.stack((rem_rec_bin, epoc_np, trial_np))\n",
    "\n",
    "n = len(trial_np)  # Number of trials\n",
    "num_samples = int(0.2 * n)  # 20% of the number of trials\n",
    "\n",
    "# Generate random numbers\n",
    "random_numbers = np.random.randint(0, n, num_samples)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train = X[random_numbers, :]\n",
    "\n",
    "# 1. Define the parameters, either variable or fixed\n",
    "for model in models:\n",
    "    cebra_model = cebra.CEBRA(\n",
    "        model_architecture = model,\n",
    "        output_dimension = 4,\n",
    "        learning_rate = 3e-4,\n",
    "        time_offsets = 10,\n",
    "        max_iterations = 10000,\n",
    "        temperature_mode = \"auto\",\n",
    "        distance = \"cosine\", \n",
    "        batch_size = 2048,\n",
    "        conditional=\"time_delta\",\n",
    "        num_hidden_units=128,\n",
    "        verbose = True)\n",
    "    cebra_model.fit(np.transpose(X_train), np.transpose(y_train))\n",
    "    cebra_time = cebra_model.transform(np.transpose(X_train))\n",
    "    embeddings.append(cebra_time)\n",
    "    \n",
    "    save_file = f\"saved_models/{model}.pt\"\n",
    "    cebra_model.save(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "y = trial_np[(epoc_np == 1) | (epoc_np == 2) | (epoc_np == 3) | (epoc_np == 4) | (epoc_np == 5)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(embeddings[i][:,0], embeddings[i][:,1], embeddings[i][:,2], c=y, cmap='jet')\n",
    "ax.set_xlabel('CEBRA1')\n",
    "ax.set_ylabel('CEBRA2')\n",
    "ax.set_zlabel('CEBRA3')\n",
    "ax.set_title('CEBRA (Firing Rate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the loss \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(cebra_model.state_dict_['loss'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifolds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
